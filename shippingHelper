
from genericpath import samefile
from json import tool
from optparse import TitledHelpFormatter
from timeit import repeat
from tkinter import W
import nltk
# from nltk.corpus import stopwords
import re
global size_of_item
titles_and_brands = []
titles_no_brands = []
updated_title_list_lower = ['nascar chevrolet racing fire dice shirt xl', '49er logo 7 xl vintage 35', "80's snowbird shirt large", '2003 korn deadstock take a look in the mirror 25 xl and xxl', '2003 nascar chase tony stewart home depot large 20', '2005 white sox world champions xl distressed 35', '2006 diabetes l', '2006 men frozen four hockey college xl', '2006 wisconsin hockey xl', '2008 nascar chase camo earnhardt shirt xl', '2009 pantera deadstock l 25', '2016 championship cubs m world series mlb', 'acme wiley coyote 2xl', 'adidas nutrition facts l', 'adidas rose bowl football m', 'adventure time l', 'adventure time large', 'aerosmith 2002 deadstock medium 25', 'alice cooper 2009 tour ds xl 25', 'american mickey l vintage', 'art shirt one size fits all xl', 'artistic lion m', 'aztec l', 'back to the future retro large', 'basketball tournament xl', 'bass pro shop medium', 'bead necklace shirt l w/ krewe of cheeseheads', 'bellspout racing m nascar', 'big dog large embroidered', 'black label society xl deadstock 25 ', 'blue nike shirt large', 'bob ross 2xl', 'bob ross 2xl piece', 'boba fett xl 2010', 'boilers purdue logo athletic m', 'bon jovi because we can tour 2013 xl', 'boyz n the hood 4x', 'breaking bank large', 'buck hunting l made in usa single stitch', 'bucket of blood s', 'chi chi get the yayo xl', 'chicago cubs lee sports xl w/ stainage', 'clemson medium college shirt', 'cloud 9 tiger xl', 'columbia green l', 'coors light 2xl slight paint stainage on front', 'dale earnhart jr 2006 nascar 2xl boxy fit', 'dale jr green xl', 'danzig legacy 2011 deadstock xl 25', 'darth tater xl', 'daytona usaa racing xl', 'disney magic kingdom medium', 'disney mickey bowlorama xl', 'disturbed 2006 tour 2xl deadstock', 'dodgers l', 'donald duck disney nyc xl', 'dragon racing fuel m', 'drink moxie 2xl', 'dylan mccarthy racing m', 'effortless m', 'fast and furious retro medium', 'fight or die xl', 'fnaf pizza cartoon large', 'full throttle biker bar medium', 'full throttle m', 'future forward xl shirt', 'g3 sports 2xl boston bruins', 'geek squad xl', 'geometrical tree large', 'glamis sand dune l shirt', 'gm card shirt xl', 'green day m 2009', 'griswold christmad red xl', 'guess green large stripe', 'guns n roses 2009 super slim long fit 2x 25', 'hard rock cafe brown 2xl', 'hard rock canada', 'harley punta cana xl tank top', 'holley ls fest small 2018', 'honor the firekeepers xl vintage sleeveles w/ stain', 'horseradish festival shirt m', 'i came i sawed i fixed xxl vintage', 'i triple dog dare you xl a christmas story', 'its safe to talk about my safety wisconsin medium vintage', 'jack daniels xl', 'jansport mediun fly gear', 'jimmie johnson winner circle xl and xxl', 'jimmy buffet 2007 medium', 'jimmy johnsons xl 48', 'jordan xxl red tree', 'junior leader yellow eagle xl', 'kaleb racing medium shirt', 'kenseth 2x', 'kobe bryant muppet l', 'korea vet 2xl', 'korn 2xl deadstock graffiti shirt y2k 25', 'korn 2009 bitch we have a problem tour 2x deadstock 30', 'korn madcatt bundle 3x 2x', 'kyke busch joe gibbs racing nascar 2xl 10', 'lawrence university xl shirt', "led zeppelin 2000's ds small 25", 'led zeppelin retro l', 'lime green pepsi shirt m', 'maddcatt xxxl martial arts shirts', 'matt kenseth nascar 2xl', 'mb baseball xl', 'mbna baseball xl', 'michelin bike racing xl', 'millennium falcon large retro old navy star wars tour shirt large', 'miller lite large', 'monopoly make it rain m', 'mossy oak xl', 'mountain medium with flaw', 'mustang m sonoma', 'nascar 2006 carl edwards xxl', 'nascar 2007 daytona triple header 3xl', 'nascar bubba wallace petty racing l', 'nascar jimmy johnson 2x 13', 'nascar junkie m winner circle', 'nascar winner circle xl johnson 48', 'new york donald duck xl', 'nickelodeon l', 'nike 1-72 2xl', 'nike blue xl', 'nike youth xl mens small', 'nile river medium', 'nissan 350z l', 'nonpoint band giant tag xl ds 25', 'nuno bettencourt band shirt size medium front and back 30', 'ohio state buckeyes xl', 'oktoberfest m', 'one piece straw hat crew m', 'oregon state football xxl nike #21', 'packers liquid blue style large 12', 'packers logo 7 xl 10', 'packers nfc nfl xl', 'peace love beaver shirt l', 'pink floyd dark side of moon l 2013 25', 'pirates of the caribbean medium disney 40', 'planet hollywood small 1991', 'primal scream deadstock xl', 'puddle of mudd m xl #1 30 ', 'puerto vallarta large', 'quicksilver xl', 'racing jimy owens l', 'realtree duck hunting shirt xl', 'rob zombie 2006 xl ds 30', 'rob zombie 2012 xl ds 30', 'rob zombie live deadstock xl 30', 'rock paper scissor large', 'rose bowl wisconsine embroidery 2000 xl', 'sandlot l', 'schrader small racing shirt', 'scorpions large deadstock humanity hour  20', 'seattle summit m', 'sepultra large band shirt 90', 'sf giants construction shirt xl', 'shoe box xl russel', 'shut up and fly xl', 'sky coaster xl', 'solid rock no limit festival shirt large', 'sp tennis medium', 'stanford russel m college shirt', 'star wars large retro very very thin and longer fit sleepshirt', 'star wars own every moment xl', 'stones 2019', 'summit lambdas 2001 m vintage', 'super bowl xlv packers shirt 2xl', 'switchfoot deadstock t shirt medium 25', 'syracuse medium orange', 'talladega speedway nascar 3xl', 'tampa bat bucs logo athletic xl 10 ', 'team sylvanua #48 racing l', 'the beatles abbey road large retro', 'the idiots believe large', 'the office xl', 'the office xl thin material', 'the shoe box black earth xl russel', 'to infinity and beyond l', 'toe jones xl vintage band', 'tony stewart xxl nascar shirt bass pro shop', 'trans siberan orchestra 2xl', 'university of notre dame small champion', 'vintage champion cornell medium', 'walker weasel l', 'walking dead xl', 'washington dc xl embroidery', 'whos the master shonuff? 2xl', 'winchester ammunition xl', 'wisconsin basketball championship xl badger', 'wisconsin ginseng festival l', 'wisconsin russell college l', 'wisconsine cornhuskers xl fired up', 'wisonain badgers shir xl', 'yale xl college shirt', 'yankees center swoosh xl', 'yellowstone m', 'zimmerman xl mlb', 'zz top xl club tacos 2006 w/ stainage']
brandss = {
    'disney items':['goofy', 'mickey', 'duck', 'disney', 'star'],
    'brands':['russel', 'jordan', 'quicksilver', 'hard', 'jimmy buffet', 'liquid', 'logo 7', 'adidas', 'guess', 'harley', 'nike', 'reebok', 'nfl', 'russell', 'adidas', 'jordan' 'levi', 'levi\'s', 'looney tunes', 'tommy', 'mitchell', 'marvel', 'nba', 'warner', 'columbia', 'starter', 'lucky brand', 'old navy', 'nautica', 'true religion', 'champion', 'guess', 'patagonia', 'timberland', 'american eagle', 'fashion nova', 'nutmeg', 'ralph lauren', 'santa cruz', 'under armour', 'billabong', 'calvin klein', 'chaps', 'chalk line', 'bke', 'bongo', 'lee', 'polo ralph lauren', 'j crew', 'hollister', 'jerzees', 'hard rock cafe', 'fila', 'coogi', 'carhartt', 'calvin klein'],
    'nfl' :['bucs', 'cardinals', 'falcons', 'raven', 'bills', 'panthers', 'bears', 'bengals', 'browns', 'cowboys', 'broncos', 'lions', 'packers', 'texans', 'colts', 'jaguars', 'chiefs', 'raiders', 'rams', 'chargers', 'dolphins', 'vikings', 'patriots', 'saints', 'giants', 'jets', 'eagles', 'steelers', '49ers', 'seahawks', 'buccaneers', 'titans', 'commanders', 'redskins', '49er'],
    'nba':['76ers', 'hawks', 'bucks', 'bulls', 'cavaliers', 'celtics', 'clippers', 'grizzlies', 'heat', 'hornets', 'jazz', 'kings', 'knicks', 'lakers', 'magic', 'mavericks', 'nets', 'nuggets', 'pacers', 'pelicans', 'pistons', 'raptors', 'rockets', 'spurs', 'suns', 'thunder', 'timberwolves', 'trailblazers', 'warriors', 'wizards'],
    'band':['korn', 'slipknot', 'rob', 'roses', 'nonpoint'],
    'harley':['harley', 'davidson'],
    'nicecar':['busch', 'matt', 'nascar', 'tony', 'dale', 'jimmy', 'johnson', 'jimmie', 'fireball roberts', 'carl long', 'fred lorenzen', 'david reutimann', 'richard childress', 'ned jarrett', 'kyle petty', 'ricky rudd', 'adam petty', 'joe weatherly', 'donnie allison', 'dave marcis', 'tim richmond', 'bobby labonte', 'ricky craven', 'kyle busch', 'geoff bodine', 'bobby allison', 'joey logano', 'junior johnson', 'todd bodine', 'kenny wallace', 'carl edwards', 'denny hamlin', 'jamie mcmurray', 'benny parsons', 'kevin harvick', 'lee petty', 'jeff burton', 'david pearson', 'kurt busch', 'kenseth', 'terry labonte', 'michael waltrip', 'kasey kahne', 'earnhardt', 'cale yarborough', 'alan kulwicki', 'tony stewart', 'jimmie johnson', 'rusty wallace', 'darrell waltrip', 'davey allison', 'dale jarrett', 'mark martin', 'jeff gordon', 'bill elliott', 'dale earnhardt', 'richard petty'],
    'looney tunes':['acme', 'tweety', 'looney tunes', 'taz', 'sylvester'],
    'mlb':['angels', 'astros', 'athletics', 'jays', 'braves', 'brewers', 'cardinals', 'cubs', 'yankee', 'diamondbacks', 'dodgers', 'giants', 'guardians', 'mariners', 'marlins', 'mets', 'nationals', 'orioles', 'padres', 'phillies', 'pirates', 'rangers', 'rays', 'sox', 'reds', 'rockies', 'royals', 'tigers', 'twins', 'sox', 'yankees'],
    'other sport':['hockey', 'golf', 'crochet'],
    'college wear': ['wisconsin', 'michigan', 'stanislaus', 'uc', 'berkeley', 'ucla', 'mjc']
}
sizes = {
    '4XL' :['4x', '4xl', 'xxxxlarge', 'xxxxl'], 
    '3XL' :['xxxl', ' xxxlarge', '3xl', ' 3xlarge', '3x'], 
    '2XL' :['xxlarge' ' 2xlarge', '2xlarge', '2x', 'xxl', '2xl'], 
    'XL' :['xl', 'xlarge'], 
    'LARGE' :['large', 'l'],
    'MEDIUM' :['m', 'medium'], 
    'SMALL' :['small', ' s']
}
count = 0
# stop_words = set(stopwords.words('english'))
new_key = list(brandss.values())
new_size = list(sizes.values())
numb = list(range(8, 48))
number = list(range(50, 300))
numberss = numb + number
stringed_numbers = [str(x) for x in numberss]
word_title_list = []
list_with_only_title = []
list_with_only_title2 = []
updated_list_without_duplicates1 = []
final_result_updated_list = []
updated_list_without_duplicates3 = []
updated_list_without_duplicates4 = []
word_key_list = []
prices_with_index = []
matches = []
non_matches= []
identify_price_list = []
all_key_total = []

for new_keys in new_key:
    for newer_keys in new_keys:
        all_key_total.append(newer_keys)
        
#function to match words with brandss value
def repeating_list(listing):
    for i in listing:
        print(i)
    print(len(listing))

def enumeration(listing):
    for i in range(len(listing)):
        ii = i + 1
        si =  ii, listing[i]
        prices_with_index.append(si)
titles_with_no_keys = []
def difference_btwn_2_list():
    titles_with_no_key = list(set(updated_title_list_lower) - set(beginning_title_no_dup))
    for titles in titles_with_no_key:
        titless = "??", titles
        titles_with_no_keys.append(titless)
    repeating_list(titles_with_no_keys)

pattern_count = 0
def identify_price(sentence):
    global pattern_count
    global pattern
    pattern = re.findall(r"[^#09847-]\d{2}$", sentence)
    
    if pattern:
        patter = [i.strip(' ') for i in pattern] 
        
        if len(patter[0]) < 3:
            matches.append(patter)
            # pattern2 = patter.replace("[' ", "")
            patte = patter, sentence
        else: 
            updated_title = (titled) + " Confirm Price:"
            non_matches.append(updated_title)
            patte = "confirm price " + sentence
    else:
        pattern = "??"
        updated_title = (titled) + " Needs Price:"
        non_matches.append(updated_title)
        patte = "need price " + sentence
    pattern_count += 1
    if patte not in identify_price_list:
            identify_price_list.append(patte)
    return pattern

size_list_titles = [] 
size_list = []
size_count = 0
sizing = 0
def identify_size(wwww):
    global size_of_item
    global size_count
    global sizing
    global titled
    global ww
    global www
    run_once = 0
    if run_once == 0:
        for new_sizes in new_size:
            for newer_sizes in new_sizes:
                if newer_sizes in wwww:
                    if newer_sizes in sizes['4XL']:
                        size_of_item = '4XL' 
                    elif newer_sizes in sizes['3XL']:
                        size_of_item = '3XL'
                    elif newer_sizes in sizes['2XL']:
                        size_of_item = '2XL'
                    elif newer_sizes in sizes['XL']:
                        size_of_item = 'XL'
                    elif newer_sizes in sizes['LARGE']:
                        size_of_item = 'LARGE'
                    elif newer_sizes in sizes['MEDIUM']:
                        size_of_item = 'MEDIUM'
                    elif newer_sizes in sizes['SMALL']:
                        size_of_item = 'SMALL'
                    else:
                        size_of_item = '??'
                    size_layout = {
                        'title': titled,
                        'size': size_of_item
                    }
                    sizing += 1
                    if titled not in size_list_titles:
                        size_list.append(size_layout)
                        size_list_titles.append(titled)
                        size_count += 1
                    # else:
                    #     print(titled)
                    #     print("OOOOOOOOOOOOOOOPS")
                    run_once = 1
                    # return size_of_item
title_count = 0
pre_title_count = 0
word_title_only_list = []
beginning_title_no_dup = []
beginning_tuple_no_dup = []
no_beginning_title_no_dup = []
no_beginning_tuple_no_dup = []
no_key_list = []
overall_titles = []
new_overall_titles = []

count = 0
def identify_brand(nw):
    global title_count
    global pattern
    global word_key
    global titled
    global size_of_item
    global word_title_only_list
    global pre_title_count
    global word_title_layout
    global count
    global tw_tuple
    value_count = 0
    run_once = 0
    if run_once == 0:
        if value_count < 2:
            for key in all_key_total:
                if key in titled:
                    value_count += 1
                    if titled not in overall_titles:
                        tw_tuple = key, titled
                        overall_titles.append(titled)  
                        beginning_tuple_no_dup.append(tw_tuple)
                        beginning_title_no_dup.append(titled)
     
            ##fixed the problem but now need to link this, which separates strings with a keyword and ones without, take the one with
            # and create a default "??" for those w/o a key,
            #I have the code to identify the keyword, and print the keyword, with the layout
            

            # else:
            #     print("nothing", nw)

            # if individual_word in all_key_total and len(individual_word) > 3:
            #     tw_tuple = individual_word, titled
            #     if nw not in in_newer_keys_title:
            #         in_newer_keys_title.append(titled)
            #         in_newer_keys.append(tw_tuple)
            #         ww_split = individual_word.split(" ")
                    
            #     else:
            #         print("oops")
            #         count +=1
            #         for www in ww_split:
            #             if len(www) >= 2:
            #             ###why is there multiple of the same sentences????
            #                 title_count += 1
            #                 if www in brandss['disney items']:
            #                     word_key = "disney"
            #                 elif www in brandss['brands']:
            #                     word_key = "brands"
            #                 elif www in brandss['nfl']:
            #                     word_key = "nfl"
            #                 elif www in brandss['nba']:
            #                     word_key = "nba"
            #                 elif www in brandss['band']:
            #                     word_key = "band"
            #                 elif www in brandss['harley']:
            #                     word_key = "harley"
            #                 elif www in brandss['nicecar']:
            #                     word_key = "nascar"
            #                 elif www in brandss['looney tunes']:
            #                     word_key = "looney tunes"
            #                 elif www in brandss['mlb']:
            #                     word_key = "mlb"
            #                 elif www in brandss['other sport']:
            #                     word_key = "other sport"
            #                 elif www in brandss['college wear']:
            #                     word_key = "college wear"
            #                 else:
            #                     word_key = '????'       
            #                 print(word_key)
            #                 word_title_layout = {
            #                     "numbered": title_count,
            #                     "price": pattern,
            #                     "title": titled,
            #                     "word value": www,
            #                     "word key": word_key,
            #                     "size": size_of_item
            #                                         }
            #                 pre_title_count += 1
            #                 if titled not in word_title_only_list:  
            #                     word_title_only_list.append(titled)
            #                     word_title_list.append(word_title_layout)
            #                 run_once = 1
            # else:
            #     print("oosssps")
            #     count += 1

################################
#MAIN CHUNK OF CODING
################################
title_len = 0
print("YUHHHHHHHHHHHHHs")
for titled in updated_title_list_lower:
    title_words = titled.split(" ")
    identify_price(titled)
    identify_size(title_words)
    identify_brand(title_words)
difference_btwn_2_list()

#that method worked like i predicteds, i used the list with keys, suvtracted to the list 
#overall list, which returned all the strings with no keys
#so now i must comvine both lists with strings in alphavetical order, then make it acesivle
#with the overall layout in vrand that I must uncomment as well,
#I was trying to do too muich the solution was super simple, I need to stop trying to
#think outside the vox too much if the solution is there then it is there
#but hyeah my eyes hurt mow so i will ve hitting the hay for the time veing until then coding software
#they will make me a decent amount of moeny
#steps make compativle with depop first, then with that go onto other sites
#and branch out from there
#what would be even better is having all the info on one main page, rather than having
#to go on each individual page to grav your info, its all in there,
#can identify if one has more than the other, which sites sell for more, and of what they sell more in
#can access a lot of data for me that I can then ship off tbut i am ready, this will vbe amao vig companies in terms of what is
#how and what is not, but I get the feeling that all these sites might be doing that already,
#but you never know so i will look into that
#overall this is all coming out nice and super excitged for hwo the end result will look
#taking a lot longer than expected tho, i thought i would finihs this last week, vut will in fact take a few more weeks most likely
#

    # for ww in title_words:
#     #     
# # print('beggining')
# repeating_list(beginning_tuple_no_dup)
# # print("no")
# # repeating_list(no_beginning_tuple_no_dup)
# # repeating_list(no_key_list)
# repeating_list(overall_titles)
# repeating_list(updated_title_list_lower)

# repeating_list(identify_price_list)
# repeating_list(word_title_list)
# print(pattern_count, 'pattern count')
# print(title_count, 'title count')
# print(pre_title_count)
# print(title_len)
# print(len(title_words))
# print(title_words)
# repeating_list(size_list)
# print(sizing)
# print(title_count)

# repeating_list(in_newer_keys)
# print(pre_title_count)
# repeating_list(in_newer_keys_title)

#THOUGHTS ON PROJECT
# Just fixed the identify_size function, was pretty difficutl, but did it and was able to clean up the code in it a bit too,
# identify price is correct too, gives a full 199
# each of these are off by a few so i got to figure out how and why they are off by a bit
# identify_brand is still only returning half of the total, but its good that price and size are taken care of,
# numbered should be easy, title too
# other than figuring out how to only get one sentence to pass through rather than like the same one 6 times but i think i can use the samefile
# filtering method I used in size definition, 
# also am going to need the pictures from it to, adn to be able to transfer,
# i dont want my computer getting stormed with pics like my phone, so i need to be able to go through files too, and i need to properly install my hard drive
#then once that is done i can create an overall layout and enter that in to a google shes
