from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import Select
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time
import requests
from bs4 import BeautifulSoup
from selenium.common.exceptions import NoSuchElementException
import codecs
import re
import json
import sqlite3
import emoji
from PyQt5.QtWidgets import QApplication
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import traceback
import unicodedata
# new accounts: help_a_pup_out_vintage, grung3g1rl, 864vintage, thredthrifts, rodeliojrr, officialkaiser, retroshyt
# gibbocreps modernthreads; 6803. M= 600,  pqgoods, jessieq 20847 brothership pnwvintage lakethriftz thekindfind lufinds  lonewolfvintagellc scottsupply, everybodyhatesx
#  
# indiedreamthrift(girls)  viasoul  twinflames  redrailvintage   modernthreads  fewandfarvintage   fleurre  vintagevortex_  lonewolfvintagellc,,   , , , 615collection, _realvintage, lilsadpapi, sevindaysteals, yourgrandpasstyle,thriftedgoodiez, untruereligiontr  23rdandvintage, gibbocreps, dominickatencio

#_realvintage, isellclothes2001
account_name = '_realvintage'
# account_name = 'isellclothes2001' 
print(account_name)
print(account_name)
print(account_name)
chrome_options = Options()
# chrome_options.add_argument("--headless")  # Run in headless mode
# chrome_options.add_argument("--disable-gpu")
chrome_options.add_experimental_option("detach", True)
driver = webdriver.Chrome("D:\\Selenium_python2\\chromedriver.exe", chrome_options=chrome_options)
driver.get("https://www.depop.com/" + account_name + '/')
time.sleep(2)
wait = WebDriverWait(driver, 20)

depop_title_list = []
all_titles = []
depop_brand_list = []
depop_men_or_wmn_list = []
depop_gen_category_list = []
depop_sub_category_list = []
depop_size_list = []
depop_condition_list = []
depop_images_list = []
depop_image_len_list = []
depop_price_list = []
depop_style_list = []
depop_color1_list = []
depop_color2_list = []
depop_likes_list = []
depop_bag_list = []
depop_url_list = []
depop_seller_list = []

count = 0 #started from 2221
total_number_done = 1
first_run = True

def start_up():
    time.sleep(1)
    driver.find_element('xpath', '//*[@id="__next"]/div/div[2]/div[2]/button[2]').click()
    time.sleep(1.5)
    print('finish start up')

def scroll_down_script():
    only_solds = driver.find_element('css selector', '[data-testid="sold__link"]')
    only_solds.click()
    time.sleep(4)
    last_height = driver.execute_script("return document.body.scrollHeight")

    while True:
        scroll_down = driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        scroll_down
        
        try:
            load_more_button = driver.find_element('xpath', '//*[@id="products-tab"]/div/div/button')
            driver.execute_script("arguments[0].scrollIntoView(true)",load_more_button)
            time.sleep(.5)
            load_more_button.click()
        except:
            pass
        try: 
            time.sleep(.5) 
            load_more_button.click()
        except:
            pass
        # Wait for the page to load
        time.sleep(.5)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            print('the end of scrolling')
            break
        last_height = new_height

def sold_post_scraper():
    global total_number_done
    global first_run
    global count
    try:
        print('starting sold post scraper')
        posts_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
        sold_post = driver.find_elements('xpath', '//*[contains(@class, "styles__SoldOverlay")]')
        all_post = driver.find_elements('css selector', '[data-testid="primaryProductImage"]')
        print('all post', len(all_post))
        print('sold_post', len(sold_post))
        total_current_post = len(all_post) - len(sold_post)
        
        for post in range(len(all_post)):

            posts_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
            sold_post = driver.find_elements('xpath', '//*[contains(@class, "styles__SoldOverlay")]')
            driver.execute_script("arguments[0].scrollIntoView(true)",sold_post[count])
            counting_post = total_current_post + count 
            print('counting post', counting_post)
            print('posts for link', len(posts_for_link))
            post_url = posts_for_link[counting_post].get_attribute('href')
            driver.execute_script("window.open('{}');".format(post_url))
            time.sleep(2)
            driver.switch_to.window(driver.window_handles[1])
            time.sleep(1)
            try:
                sold_post_banner = driver.find_element('css selector', '[data-testid="button__sold"]')
                print('IT IS A SOLD POST')
                post_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
                posts_for_link = post_for_link[1:]
                # print('post_for_link: ', len(post_for_link))
                # print('posts_for_link: ', len(posts_for_link))

                all_post = driver.find_elements('css selector', '[data-testid="primaryProductImage"]')
                print(account_name)
                print('all post', len(all_post))

                title_parsing()           
            except:
                driver.close()
                time.sleep(.5)
                driver.switch_to.window(driver.window_handles[0])
                pass
            total_number_done += 1
            count += 1
        else:
            pass
    except Exception as e:
        traceback.print_exc()
        print('Failed to load, or I purposely closed it, Uploading the data')
        print(e)
        sqlite_database_for_depop()
        first_run = False

def hashtag_parser(word):
    global account_name
    global overall_title
    global title_of_item
    ind_title = []
    try:
        wordd = word.split("PLEASE READ CAREFULLY!! Some items may have unlisted markings, but for the most part all marking would be listed. These clothes are often old and used, so tend to not be in pristine condition. Most items that are listed here will by default be used, unless stated otherwise. Items have not been washed so we also highly recommend that you wash before putting it on.  All items have been handpicked by us. Thank you for choosing to support us at RealVintage._ and if there is anything we can do to make your experience better feel free to send us a message! We also give large discounts if purchasing stuff in bulk.")
    except:
        wordd = word
    for letter in wordd:
        if letter != '#' or ',' or '\n' or "PLEASE":
            ind_title.append(letter)
        else:
            overall_title = ''.join(ind_title)
            print(overall_title)

            if overall_title not in all_titles:
                all_titles.append(overall_title)
            break
    title =''.join(ind_title)
    item_title = title.split('#')[0].strip()
    title_of_item = item_title.replace('\n', ' ')
    try:
        title_of_item = title_of_item.encode('ascii', 'ignore').decode('unicode_escape')
        depop_title_list.append(title_of_item)
        print(title_of_item)
    except:
        depop_title_list.append(title_of_item)
        print(title_of_item)

gender_cat_1 = 0
gender_cat_3 = 0
gender_none = 0
def title_parsing():
    global gender_none, gender_cat_1, gender_cat_3
    global total_number_done
    global count
    global title_of_item
    print('start title parsing')   
    time.sleep(1)  
    script_tag = driver.find_element('css selector', "[data-testid='meta-schema__json-ld']")
    print(script_tag.text)
    script_content = script_tag.get_attribute("innerHTML")
    data = script_content.encode('ascii', 'ignore').decode('unicode_escape')
    data = json.loads(script_content)
    
    #price
    price = data['offers']['price']
    print(price)
    try:
        price = int(price)
    except:
        price = float(price)
    if price >= 99999:
        print('Meet the Seller')
        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        print('seller post')
        time.sleep(2)
        return
    else:
        depop_price_list.append(price)
        
        #url
        url_string = data['offers']['url']
        print(url_string)
        depop_url_list.append(str(url_string))

    # Extract the name category
        item_title = data["description"]
        hashtag_parser(item_title)
        
        # seller account
        depop_seller_list.append(account_name)

        #images
        images = data['image']
        # print(images)
        depop_images_list.append(images)
        depop_image_len_list.append(int(len(images)))

        #condition
        try:
            condition = driver.find_element('css selector', "[data-testid='product__condition']")
            # print(condition.text)
            depop_condition_list.append(str(condition.text)) 
        except:
            depop_condition_list.append(' ')   
             
        #size
        #will leave this blank so i can fill it in with the personal scraper. Just need to find the corresponding title to match them together
        depop_size_list.append(' ')
        #styles
        try:
            style_color = driver.find_element('css selector', '[data-testid="product__colour"]')
            # print(style_color.text)
        
            #color
            # try:
            text_of_color = style_color.text
            # print(text_of_color)
            colors = text_of_color.split(', ')
            color1 = colors[0] 
            # print('color1', color1)
            color2 = colors[1] if len(colors) > 1 else ''
            depop_color1_list.append(color1)
            depop_color2_list.append(color2)

        except Exception as e:
            depop_color1_list.append('')
            depop_color2_list.append('')
            print(e)
            
        category = driver.find_elements('xpath', '//*[contains(@class, "BreadcrumbLink")]')
        if category[1].text == 'Brand':
            brand = category[2].text
            depop_brand_list.append(brand)
            print(brand)
        else:
            depop_brand_list.append('')
            print(' no brand')

        # specific category  

         
        try:
            men_or_wmn_wear = category[3]
            men_or_wmn_text = men_or_wmn_wear.text
            if men_or_wmn_text in ['Menswear', 'Womenswear', "Kids"]:
                # print('there is brand')
                gender_cat_3 += 1
                print('gender_cat_3', gender_cat_3)
                depop_men_or_wmn_list.append(men_or_wmn_text)
                index = 3
                
            elif category[1].text in ['Menswear', 'Womenswear', "Kids"]:
                # print('NO BRAND')
                men_or_wmn_wear = category[1]
                men_or_wmn_text = men_or_wmn_wear.text
                gender_cat_1 += 1
                print('gender_cat_1', gender_cat_1)
                depop_men_or_wmn_list.append(men_or_wmn_text)
                index = 1
        except:
            print('there is no men or woman in this')
            gender_none += 1
            print('gender_none', gender_none)
            depop_men_or_wmn_list.append('')
        print('men_or_wmn text ' + men_or_wmn_text)

        #general category
        try:
            gen_category = category[index + 1]
            gen_category_text = gen_category.text
            # print('head_category_text ' + gen_category_text)
            depop_gen_category_list.append(gen_category_text)
        except:
            # print('no general category' + str(count))
            depop_gen_category_list.append(' ')
        try:

            sub_category = category[index + 2]
            sub_category_text = sub_category.text
            # print('sub_category_ ' + sub_category_text)
            depop_sub_category_list.append(sub_category_text) 
        except:
            depop_sub_category_list.append(' ')  
            # print('No specific sub category for ' + str(count))        
  
        all_text = driver.find_element('xpath', "/html/body").text
        
        #total in bag
        bag_match = re.search(r'\d{1,3}$', all_text)

        if bag_match:
            number = int(match.group())
            depop_bag_list.append(number)
            # print('in bag ' + str(number))
        else:
            # print('no bag')
            depop_bag_list.append(0)
        #total likes
        match = re.search(r'\b\d{1,3}\b(?=\s+likes)', all_text)
        if match:
            likes = int(match.group())
            # print('likes ' + str(likes))
            depop_likes_list.append(likes)
        else:
            depop_likes_list.append(0)
            # print("No likes found.")
        # driver.switch_to.window(driver.window_handles[1])
        driver.close()
        time.sleep(1)
        driver.switch_to.window(driver.window_handles[0])
        print(' ')
        print('total_number_done' + str(total_number_done))
        print('count' + str(count))
        print('end title parsing')

def checking_all_match():
    if len(depop_men_or_wmn_list) == len(depop_title_list) and len(depop_gen_category_list) and len(depop_sub_category_list) and len(depop_condition_list) and len(depop_brand_list) and len(depop_images_list) and len(depop_image_len_list) and len(depop_price_list) and len(depop_color1_list) and len(depop_color2_list) and len(depop_likes_list) and len(depop_bag_list) and len(depop_url_list):
        print('This is all good')
        print(len(depop_title_list))
        print('this the max count')
    else:
        print('Fix this')
        print('depop total titles ' + str(len(depop_title_list)))
        print('depop men or women ' + str(len(depop_men_or_wmn_list)))
        print('depop gen category list ' + str(len(depop_gen_category_list)))
        print('depop sub category_list ' + str(len(depop_sub_category_list)))
        print('depop brand_list ' + str(len(depop_brand_list)))
        print('depop url list'+ str(len(depop_url_list)))
        print('depop_condition_list ' + str(len(depop_condition_list)))
        print('depop image_list ' + str(len(depop_images_list)))
        print('depop image len_lists ' + str(len(depop_image_len_list)))
        print('depop price list ' + str(len(depop_price_list)))
        print('depop color1 list ' + str(len(depop_color1_list)))
        print('depop color2 list ' + str(len(depop_color2_list)))
        print('depop likes list ' + str(len(depop_likes_list)))
        print('depop bag list ' + str(len(depop_bag_list)))

def sqlite_database_for_depop():
    global account_name
    global first_run
    combined = zip(depop_title_list, depop_price_list, depop_likes_list, depop_bag_list, depop_brand_list, depop_url_list, depop_seller_list, depop_men_or_wmn_list, depop_gen_category_list, depop_sub_category_list, depop_size_list, depop_condition_list, ['; '.join(x) for x in depop_images_list], depop_image_len_list, depop_color1_list, depop_color2_list)
    combined_list = list(combined)
    
    connection = sqlite3.connect('D:\\Selenium_python2\\Depop_database.db')
    cursor = connection.cursor()

  
    # Create a new table with an auto-incrementing primary key
    if first_run == True:
        print('')# figure out a way to change the table name, dp_personal_sold for my stuff, dp_sold for others

        command_create = """
            CREATE TABLE IF NOT EXISTS dp_personal_sold (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                dp_title TEXT UNIQUE,
                dp_price INT,
                dp_likes INT,
                dp_bag INT,
                dp_brand TEXT,
                dp_url_list TEXT,
                dp_seller TEXT,
                dp_men_or_wmn TEXT,
                dp_gen_category TEXT,
                dp_category TEXT,
                dp_size TEXT,
                dp_condition TEXT,
                dp_images TEXT,
                dp_image_len INT,
                dp_color1 TEXT,
                dp_color2 TEXT DEFAULT ''
            )
        """
        cursor.execute(command_create)
        
        # Insert data into the new table
        command_insert = """
            INSERT OR IGNORE INTO dp_personal_sold (
                dp_title,
                dp_price,
                dp_likes,
                dp_bag,
                dp_brand,
                dp_url_list,
                dp_seller,
                dp_men_or_wmn,
                dp_gen_category,
                dp_category,
                dp_size,
                dp_condition,
                dp_images,
                dp_image_len,
                dp_color1,
                dp_color2
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        cursor.executemany(command_insert, combined_list)
        
        connection.commit()
        connection.close()
    else:
        print('already been uploaded')

start_up()
scroll_down_script()
sold_post_scraper()
checking_all_match()
sqlite_database_for_depop()

#make a count
#options for this
# can delete the whole table and create a new one from scratch?
# --- this might take much longer for the overall process since would have to scan and do repetitive stuff over and over again
# ##drop the table and create a new one


#DO THIS ONE DO THIS ONE
# or since solds will be in order can stop scanning once i get to a title that is already in my database?
# --- will need to figure this out but will save a lot more time
# ## compare the current title with ones already in and use a command like SELECT * FROM dp_personal_sold WHERE TITLE = "", and if something pops up, stop the code

# the process for this would be extract the very last title from this seller sold list, identifying to dp_seller_list and get last one, then for
# every title you extract, make sure it is not the individual one you extracted and if it is, then stop the program and continue to sqlite_database_for_depop()
