from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import Select
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
from bs4 import BeautifulSoup
import codecs
import re
import json
import sqlite3
import emoji
from PyQt5.QtWidgets import QApplication
import traceback
import unicodedata

brandss = {
    'Adidas': ['adidas', 'adida'],
    'Mitchell & Ness': ['mitchell', 'ness'],
    'Nike': ['nike', 'nik', 'acg', 'nike '],
    'J. Galt': ['j. galt'],
    'NBA': ['unk', 'nba', 'kobe', 'lebron', 'kd', '76ers', 'hawks', 'bucks', 'bulls', 'cavaliers', 'celtics', 'clippers', 'grizzlies', 'heat', 'hornets', 'jazz', 'kings', 'knicks', 'lakers', 'magic', 'mavericks', 'nets', 'nuggets', 'pacers', 'pelicans', 'pistons', 'raptors', 'rockets', 'spurs', 'suns', 'thunder', 'timberwolves', 'trailblazers', 'warriors', 'wizards'],
    'NFL': ['nfl', 'raider', 'raiders', 'packers', 'lions', 'saints', 'cardinals', 'chargers', 'bucs', 'buccanears', 'browns', 'cowboys', '49er', 'ravens', 'broncos', 'seahawk', 'seahawks', 'panthers', 'jets', 'colts', 'falcons', 'jaguars', 'jags', 'chiefs', 'bills', 'eagles', 'rams', 'titans', 'bengals', 'steelers', 'dolphins', 'patriots', 'vikings', 'commanders', 'redskins'],
    'NHL': ['nhl'],
    'MLB': ['mlb', 'angels', 'astros', 'athletics', 'jays', 'braves', 'brewers', 'cardinals', 'cubs', 'yankees', 'diamondbacks', 'dodgers', 'giants', 'guardians', 'mariners', 'marlins', 'mets', 'nationals', 'orioles', 'padres', 'phillies', 'pirates', 'rangers', 'rays', 'sox', 'reds', 'rockies', 'royals', 'tigers', 'twins', 'sox', 'yankees'],
    'Fox Racing': ['fox', 'foxracing'],
    'NASCAR': ['intimidator', 'nascar', 'busch', 'matt', 'nascar', 'tony', 'dale', 'jimmy', 'johnson', 'jimmie', 'fireball roberts', 'carl long', 'fred lorenzen', 'david reutimann', 'richard childress', 'ned jarrett', 'kyle petty', 'ricky rudd', 'adam petty', 'joe weatherly', 'donnie allison', 'dave marcis', 'tim richmond', 'bobby labonte', 'ricky craven', 'kyle busch', 'geoff bodine', 'bobby allison', 'joey logano', 'junior johnson', 'todd bodine', 'kenny wallace', 'carl edwards', 'denny hamlin', 'jamie mcmurray', 'benny parsons', 'kevin harvick', 'lee petty', 'jeff burton', 'david pearson', 'kurt busch', 'kenseth', 'terry labonte', 'michael waltrip', 'kasey kahne', 'earnhardt', 'cale yarborough', 'alan kulwicki', 'tony stewart', 'jimmie johnson', 'rusty wallace', 'darrell waltrip', 'davey allison', 'dale jarrett', 'mark martin', 'jeff gordon', 'bill elliott', 'dale earnhardt', 'richard petty'],
    'Harley Davidson': ['harley', 'davidson'],
    'Anti Social Social Club': ['anti', 'social', 'social club', 'social clubs'],
    'Arc\'tyrex': ['arc', 'tyrex', 'arctyrex', "arc'tyrex"],
    'Armani': ['exchange', 'armmani'],
    'Asics': ['asics', 'asic'],
    'BONGO': ['bongo', 'bongos'],
    'Balenciaga': ['bal', 'enciaga', 'balenciaga', 'balenci'],
    'Birkenstock': ['birks', 'birk', 'birkenstock'],
    'Calvin Klein': ['calvin', 'klein', 'calvin klein'],
    'Cambridge Classics': ['cambridge', 'classics'],
    'Buckle': ['buckle', 'bke'],
    'Chalk Line': ['chalk'],
    'Champion': ['champion'],
    'Cherokee': ['cherokee'],
    'Citizens of Humanity': ['citizens', 'humanity', 'humanities', 'humanity'],
    'Coca-Cola': ['coca', 'cola', 'coca-cola'],
    'Cole Haan': ['cole', 'haan', 'colehaan'],
    'Columbia': ['columbia', 'columbi'],
    'Coogi': ['coogi'],
    'DC Comics': ['dc'],
    'Dickies': ['dickies'],
    'Disney': ['goofy', 'mickey', 'duck', 'disney', 'star', 'boba fett'],
    'Dr. Martens': ['martens', 'marten'],
    'Ecko Unltd.': ['ecko', 'unlimited', 'unltd.', 'unltd'],
    'Ed Hardy': ['hardy'],
    'Fear of God': ['fear', 'god', 'fear of god', 'fog'],
    'Forever 21': ['forever'],
    'G-III': ['g', 'iii', 'g-iii'],
    'GANT': 'gant',
    'Goodfellow & CO': ['goodfellow'],
    'Guess': ['guess'],
    'Hard Rock Cafe': ['hard', 'cafe', 'rock cafe'],
    'JNCO': ['jnco'],
    'Jerzees': ['jerzees'],
    'Jordan': ['jordan', 'jordans', 'jorda'],
    'Kappa': 'kappa',
    'LRG': ['lrg'],
    'Land\'s End': ["land's", 'lands'],
    'Levi': ['levi', 'levis', 'levi\'s'],
    'Liquid Blue': ['liquid'],
    'Looney Tunes': ['acme', 'tweety', 'looney tunes', 'taz', 'sylvester', 'jam'],
    'Lucky Brand': ['lucky'],
    'L.L. Bean': ['ll', 'bean'],
    'Lululemon': ['lululemon', 'lulu'],
    'Marvel': ['marvel', 'spiderman', 'spider-man', 'captain america', 'thor', 'iron man', 'iron-man', 'deadpool', 'marvel'],
    'Miss Me': ['miss', 'me'],
    'Murano': 'murano',
    'Nautica': ['nautica'],
    'New Balance': ['balance'],
    'New Era': ['new era', 'era', 'newera'],
    'Nordstrom': ['nordstrom'],
    'Obermeyer': 'obermeyer',
    'Old Navy': ['oldnavy', 'old'],
    'Oskar Haug': ['haug'],
    'Patagonia': ['pata', 'patagonia'],
    'Planet Hollywood': ['planet', 'hollywood'],
    'Polo Ralph Lauren': ['polo'],
    'Primitive': 'primitive',
    'Pro Player': ['pro player'],
    'Quiksilver': ['quicksilver', 'quiksilver'],
    'RSQ': ['rsq'],
    'Ralph Lauren': ['ralph', 'lauren'],
    'Reebok': ['reebok', 'reeboks'],
    'Rocawear': ['rocawear', 'roca'],
    'Rock Revival': ['rock revival', 'revival'],
    'RVCA': 'rvca',
    'Russell Athletics': ['russell', 'russel'],
    'Salty Crew': ['salty', 'crew'],
    'Star Wars': ['star', 'wars', 'boba', 'yoda', 'mandalorian'],
    'Starter': ['starter', 'starters'],
    'Stussy': 'stussy',
    'Supreme': ['supreme'],
    'The Mountain': ['mountain', 'the mountain'],
    'The North Face': ['north', 'northface'],
    'Thrasher': 'thrasher',
    'Timberland': ['timberland', 'timbs', 'timb'],
    'Tommy Bahama': 'bahama',
    'Tommy Hilfigher': ['tommy', 'hilfiger', 'hilfigher'],
    'True Religion': ['true', 'religion'],
    'UGG': 'ugg',
    'Under Armour': ['under', 'armour'],
    'Vans': 'vans',
    'Vineyard Vines': ['vineyard', 'vines', 'vineyards'],
    'Von Dutch': ['von', 'dutch', 'vondutch'],
    'WWE': ['stone cold', 'wwe'],
    'Logo Athletic': ['logo', 'athletic'],
    'Zara': 'zara',
    'Baby Phat': 'baby',
    'American Eagle Outfitters': ['american', 'eagle'],
    'Carhartt': 'carhartt',
    'extras': ['dockers', 'eastland', 'dickies', 'apple', 'aeropostale', 'gymshark', 'guess', 'gymboree', 'ghirardelli', 
                'bebe', 'camel', 'crocs', 'clarks' 'coach', 'dior', 'footjoy', 'ferrari', 'funko', 'fendi',
                'gillette', 'gap', 'keen', 'kith', 'quicksilver', 'minecraft', 'nutmeg', 'obey', 'samsung', 'cabela', 'majestic', 'wrangler', 'woolrich', 'ariat',
                'pendleton', 'converse', 'fila', 'kangol', 'lacoste', 'playboy', 'polaroid', 'chaps', 'billabong'],
    'American Vintage': ['vintage', 'vnt', 'vtg', '90\'s'],
    }

# specify the URL you want to scrape
account_name = '_realvintage'
# account_name = 'isellclothes2001'
url = 'https://www.depop.com/' + account_name + '/'

chrome_options = Options()
chrome_options.add_experimental_option("detach", True)
driver = webdriver.Chrome("D:\\Selenium_python2\\chromedriver.exe", chrome_options=chrome_options)
# driver.maximize_window()
total_titles = 0
ovr_listings = 0

driver.get(url)

depop_brand_list = []
#both of these coppied from depopPoster with slight adjustments
def start_up():
    time.sleep(1)
    driver.find_element('xpath', '//*[@id="__next"]/div/div[2]/div[2]/button[2]').click()
    time.sleep(1.5)
    print('finish start up')

def sign_in(which_account):
    driver.find_element('xpath', '//*[contains(@class, "styles__NavLinkText")]').click()
    time.sleep(2)
    if which_account == '_realvintage':
        account_email = 'argelarroyo2001@gmail.com'
        account_password = 'Pineappleguy305'
    elif which_account == 'isellclothes2001':
        account_email = 'isellclothes2001@gmail.com'
        account_password = 'Fernanda*1979' 

    username = WebDriverWait(driver, 10).until(EC.presence_of_element_located(('xpath', '//*[@id="username"]')))
    username.send_keys(account_email)
    time.sleep(2)
    driver.find_element('xpath', '//*[@id="password"]').send_keys(account_password) 
    driver.find_element('xpath', '//*[@id="main"]/div[3]/form/button').click()
    time.sleep(20)

def picking_brand(dabrand):
    global count
    try:
        brand_down = driver.find_element('xpath', '//*[@id="listingBrands__select"]')
        brand_down.send_keys(dabrand)
        brand_down.send_keys(Keys.ENTER)
        depop_brand_list.append(dabrand)
        print('brand key has worked properly, onto the next')
        save_changes_button = driver.find_element('xpath', '//*[contains(@class, "styles__SaveButton-sc")]')
        driver.execute_script("arguments[0].scrollIntoView(true)",save_changes_button)
        time.sleep(1)
        save_changes_button.click()
        time.sleep(3)
    except:
        pass
    
current_url = driver.current_url
response = requests.get(current_url)
soup = BeautifulSoup(response.text, 'html.parser')
actions = ActionChains(driver)


def scroll_down_script():
    try:
        all_post = driver.find_elements('xpath', '//*[contains(@class, "styles__PrimaryProductImage-sc-_")]') 
        # load_more_button = driver.find_element('xpath', '//*[contains(@class, "sc-jOrMOR QkOJi")]')
        load_more_button = driver.find_element('xpath', '//*[@id="products-tab"]/div/div/button')
        while True:
            time.sleep(1)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            driver.execute_script("arguments[0].scrollIntoView(true)",load_more_button)
            time.sleep(1)
            load_more_button.click()
            try: 
                time.sleep(1) 
                load_more_button.click()
            except:
                pass
            try:
                sold_post = driver.find_elements('xpath', '//*[contains(@class, "styles__SoldOverlay")]')#MIGHT NEED TO CHANGE THIS? DEPENDING ON IF THIS IS ACCURATE CLASS FOR sold_post
                if len(sold_post) > 15:
                    print('FINALLY A SOLD POST')
                    break
                else:
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            except NoSuchElementException:
                print(len(sold_post))
                pass
    except:
        pass
        while True:
            time.sleep(1)
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            try:
                sold_post = driver.find_elements('xpath', '//*[contains(@class, "styles__SoldOverlay-")]')
                if len(sold_post) > 15:
                    print('FINALLY A SOLD POST')
                    break
                else:
                    print('NO SOLD POST YET')
            except NoSuchElementException:
                pass

count = 0
def each_post(): 
    first_post_count = 0
    global count  
    try:
        print("starting item count " + str(count))
        time.sleep(3)
        print('reading all posts')
        posts_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
        print('posts_for_link: ', len(posts_for_link))

        all_post = driver.find_elements('css selector', '[data-testid="primaryProductImage"]')
        print('all post', len(all_post))
        sold_post = driver.find_elements('xpath', '//*[contains(@class, "styles__SoldOverlay-")]')
        print('sold_post', len(sold_post))
        total_available_post = len(all_post) - len(sold_post)
        print('length of posts')
        print('total_available_post', total_available_post)
        # for i in range(7):
        for post in range(total_available_post):
            posts_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
            all_post = driver.find_elements('css selector', '[data-testid="primaryProductImage"]')
            print('posts for link', len(posts_for_link))
            print('start post ', str(count))
            try:
                driver.execute_script("arguments[0].scrollIntoView(true)",all_post[count])
                print('clicking good')
            except:
                pass
            
            time.sleep(1)
            # driver.execute_script("arguments[0].click()",all_post[count])
            post_url = posts_for_link[count].get_attribute('href')
            time.sleep(3)
            # driver.execute_script("window.open('" + post_url + "', '_blank');")
            driver.execute_script("window.open('{}');".format(post_url))
            time.sleep(2)
            # switch to the second tab
            driver.switch_to.window(driver.window_handles[1])

            post_for_link = driver.find_elements('css selector', '[data-testid="product__item"]')
            posts_for_link = post_for_link[1:]
            print('post_for_link: ', len(post_for_link))
            print('posts_for_link: ', len(posts_for_link))

            all_post = driver.find_elements('css selector', '[data-testid="primaryProductImage"]')
            print('all post', len(all_post))

            # time.sleep(2)
            try:
                title_parsing()
            except:
                driver.close()
                driver.switch_to.window(driver.window_handles[0])
            count += 1
    except Exception as e:
        traceback.print_exc()
        print('Failed to load, or I purposely closed it, Uploading the data')
        print(e)
        sqlite_database_for_depop(account_name)

depop_title_list = []
all_titles = []
def hashtag_parser(word):
    global overall_title
    global title_of_item
    ind_title = []
    # time.sleep(2)
    try:
        wordd = word.split("PLEASE READ CAREFULLY!! Some items may have unlisted markings, but for the most part all marking would be listed. These clothes are often old and used, so tend to not be in pristine condition. Most items that are listed here will by default be used, unless stated otherwise. Items have not been washed so we also highly recommend that you wash before putting it on.  All items have been handpicked by us. Thank you for choosing to support us at RealVintage._ and if there is anything we can do to make your experience better feel free to send us a message! We also give large discounts if purchasing stuff in bulk.")
    except:
        wordd = word
    for letter in wordd:
        if letter != '#' or ',' or '\n' or "PLEASE":
            ind_title.append(letter)
        else:
            overall_title = ''.join(ind_title)
            print(overall_title)

            if overall_title not in all_titles:
                all_titles.append(overall_title)
            break
    title =''.join(ind_title)
    item_title = title.split('#')[0].strip()
    title_of_item = item_title.replace('\n', ' ')
    try:
        title_of_item = title_of_item.encode('ascii', 'ignore').decode('unicode_escape')
        depop_title_list.append(title_of_item)
        print(title_of_item)
    except:
        depop_title_list.append(title_of_item)
        print(title_of_item)
        
depop_men_or_wmn_list = []
depop_gen_category_list = []
depop_sub_category_list = []
depop_size_list = []
depop_condition_list = []
depop_images_list = []
depop_image_len_list = []
depop_price_list = []
depop_style_list = []
depop_color1_list = []
depop_color2_list = []
depop_likes_list = []
depop_bag_list = []
depop_boosted_list = []
depop_url_list = []
def title_parsing():
    global ovr_listings
    global count
    global title_of_item
    print('start title parsing')   
    time.sleep(1)  
    script_tag = driver.find_element('css selector', "[data-testid='meta-schema__json-ld']")
    print(script_tag.text)
    script_content = script_tag.get_attribute("innerHTML")
    data = script_content.encode('ascii', 'ignore').decode('unicode_escape')
    data = json.loads(script_content)
    
    #price
    price = data['offers']['price']
    print(price)
    if price == '99999.00':
        print('Meet the Seller')
        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        time.sleep(2)
        return
    else:
        depop_price_list.append(price)
        
        #url
        url_string = data['offers']['url']
        print(url_string)
        depop_url_list.append(str(url_string))

    # Extract the name category
        item_title = data["description"]
        hashtag_parser(item_title)
        
        #images
        images = data['image']
        depop_images_list.append(images)
        depop_image_len_list.append(int(len(images)))
        # print(len(images))
        #size
        try:
            condition = driver.find_element('css selector', "[data-testid='product__condition']")
            # print(condition.text)
            depop_condition_list.append(str(condition.text)) 
        except:
            depop_condition_list.append(' ')   
            
        #brand
        found_brand = False
        try:
            brand = driver.find_elements('xpath', "//*[contains(@class,'Link-sc-__sc-1urid-0 dDCRSY')]")
            brand = brand[0]
            brand_text = brand.text
            found_brand = True
            print('brand found ' + str(brand_text))
            print('has brand')
            depop_brand_list.append(brand_text)
        except:
            depop_brand_list.append(' ')

        # this code is to be able to change the brand if needed, will incorporate into it later, but at the moment not needed
        # except:
            # print('brand not found in dictionary')
            # brand_text = ''
            # title_of_item = title_of_item.lower().split(' ')
            # for key, value in brandss.items():
            #     if any([v.lower() in title_of_item for v in value]):
            #         print(key)
            #         if key == 'extras':
            #             print('key is extras')
            #             for v in value:
            #                 if v.lower() in title_of_item:
            #                     found_brand = True
            #                     print(v.title())
            #                     break
            #         else:
            #             if found_brand == False:
            #                 new_brand = key
            #                 print('no extra for found brand')
            #                 print(new_brand)
            #                 found_brand = True
            #             else:
            #                 new_brand = key
            #                 print('either extra or post already had a brand')
            #                 print(new_brand)
            #                 if new_brand.title() == brand_text.title():
            #                     print('new and old brand match')
            #                     depop_brand_list.append(new_brand.title())
            #                     break
            #                 else:
            #                     time.sleep(2)
            #                     print('brand was found, now need to add')
            #                     # edit_button = driver.find_element('xpath', '//*[contains(@class, "sc-gFGZVQ kPUsfy ProductOwnerstyles__ButtonEdit-sc-__evoxh9-2 ePFDlz")]')
            #                     # edit_button.click()
            #                     # time.sleep(3)
            #                     # print(new_brand)
            #                     # picking_brand(new_brand)
            #                     break                    
            # else:
            #     depop_brand_list.append(' ')

        try:
            size = driver.find_element('css selector', '[data-testid="product__singleSize"]')
            size_text = size.text
            size_value = size_text.replace('Size ', "")
            # print(size_value)
            depop_size_list.append(size_value)
        except:
            # print('no size')
            depop_size_list.append(' ')
        #styles
        try:
            style_color = driver.find_element('css selector', '[data-testid="product__colour"]')
            # print(style_color.text)
        
            #color
            # try:
            text_of_color = style_color.text
            # print(text_of_color)
            colors = text_of_color.split(', ')
            color1 = colors[0] 
            print('color1', color1)
            color2 = colors[1] if len(colors) > 1 else ''
            print('color2', color2)
            depop_color1_list.append(color1)
            depop_color2_list.append(color2)

        except Exception as e:
            print(e)
            depop_color1_list.append('')
            depop_color2_list.append('')

            # print('no color in general')
        category = driver.find_elements('xpath', '//*[contains(@class, "BreadcrumbLink")]')

        # specific category  
        try:
            men_or_wmn_wear = category[3]
            men_or_wmn_text = men_or_wmn_wear.text
            if men_or_wmn_text in ['Menswear', 'Womenswear', 'Kids']:
                # print('there is brand')
                depop_men_or_wmn_list.append(men_or_wmn_text)
                index = 3
            elif category[1].text in ['Menswear', 'Womenswear', 'Kids']:
                # print('NO BRAND')
                men_or_wmn_wear = category[1]
                men_or_wmn_text = men_or_wmn_wear.text
                depop_men_or_wmn_list.append(men_or_wmn_text)
                index = 1
        except:
            depop_men_or_wmn_list.append('')
        # print('men_or_wmn text ' + men_or_wmn_text)

        #general category
        try:
            gen_category = category[index + 1]
            gen_category_text = gen_category.text
            # print('head_category_text ' + gen_category_text)
            depop_gen_category_list.append(gen_category_text)
        except:
            # print('no general category' + str(count))
            depop_gen_category_list.append(' ')
        try:

            sub_category = category[index + 2]
            sub_category_text = sub_category.text
            # print('sub_category_ ' + sub_category_text)
            depop_sub_category_list.append(sub_category_text) 
        except:
            depop_sub_category_list.append(' ')  
            # print('No specific sub category for ' + str(count))        
  
        all_text = driver.find_element('xpath', "/html/body").text
        
        #total in bag
        bag_match = re.search(r'\d{1,3}$', all_text)

        if bag_match:
            number = int(match.group())
            depop_bag_list.append(number)
            # print('in bag ' + str(number))
        else:
            # print('no bag')
            depop_bag_list.append(0)
        #total likes
        match = re.search(r'\b\d{1,3}\b(?=\s+likes)', all_text)
        if match:
            likes = int(match.group())
            # print('likes ' + str(likes))
            depop_likes_list.append(likes)
        else:
            depop_likes_list.append(0)
            # print("No likes found.")
        
        # boosted or not 0 == False, 1 == True, 2 == Unable to Identify
        print('starting boosted finder')
        if 'Unboost listing' in all_text:
           print('unboosted listing')
           depop_boosted_list.append(1)
        elif 'Boost listing' in all_text:
            print('boosted listing')
            depop_boosted_list.append(0)
        else:
            print('unable to determine if boosted or not')
            depop_boosted_list.append(2)

        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        time.sleep(2)
        # print('end title parsing')

def checking_all_match():
    print(account_name)
    if len(depop_men_or_wmn_list) == len(depop_title_list) and len(depop_boosted_list) and len(depop_gen_category_list) and len(depop_sub_category_list) and len(depop_condition_list) and len(depop_brand_list) and len(depop_images_list) and len(depop_image_len_list) and len(depop_price_list) and len(depop_color1_list) and len(depop_color2_list) and len(depop_likes_list) and len(depop_bag_list) and len(depop_url_list):
        print('This is all good')
        print('this the max count', len(depop_title_list))

    else:
        print('Fix this')
        print('depop total titles ' + str(len(depop_title_list)))
        print('depop men or women ' + str(len(depop_men_or_wmn_list)))
        print('depop gen category list ' + str(len(depop_gen_category_list)))
        print('depop sub category_list ' + str(len(depop_sub_category_list)))
        print('depop boosted list ' + str(len(depop_boosted_list)))
        print('depop brand_list ' + str(len(depop_brand_list)))
        print('depop url list'+ str(len(depop_url_list)))
        print('depop_condition_list ' + str(len(depop_condition_list)))
        print('depop image_list ' + str(len(depop_images_list)))
        print('depop image len_lists ' + str(len(depop_image_len_list)))
        print('depop price list ' + str(len(depop_price_list)))
        print('depop color1 list ' + str(len(depop_color1_list)))
        print('depop color2 list ' + str(len(depop_color2_list)))
        print('depop likes list ' + str(len(depop_likes_list)))
        print('depop bag list ' + str(len(depop_bag_list)))

def sqlite_database_for_depop(the_table_name):
    global account_name
    combined = zip(depop_title_list, depop_price_list, depop_likes_list, depop_bag_list, depop_boosted_list, depop_brand_list, depop_url_list, depop_men_or_wmn_list, depop_gen_category_list, depop_sub_category_list, depop_size_list, depop_condition_list, ['; '.join(x) for x in depop_images_list], depop_image_len_list, depop_color1_list, depop_color2_list)
    combined_list = list(combined)
    
    connection = sqlite3.connect('D:\\Selenium_python2\\Depop_database.db')
    cursor = connection.cursor()
    table_name = 'dp_inv_' + the_table_name
    # Create a new table with an auto-incrementing primary key
    # try:
    #     command_create = f"""
    #         DROP TABLE {table_name}
    #     """
    #     cursor.execute(command_create)
    # except:
    #     pass
#easier to just drop the whole table at that point,

    command_create = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            dp_title TEXT UNIQUE,
            dp_price INT,
            dp_likes INT,
            dp_bag INT,
            dp_boosted INT,
            dp_brand TEXT,
            dp_url_list TEXT,
            dp_men_or_wmn TEXT,
            dp_gen_category TEXT,
            dp_category TEXT,
            dp_size TEXT,
            dp_condition TEXT,
            dp_images TEXT,
            dp_image_len INT,
            dp_color1 TEXT,
            dp_color2 TEXT DEFAULT ''
        )
    """
    cursor.execute(command_create)
    
    # Insert data into the new table
    command_insert = f"""
        INSERT OR IGNORE INTO {table_name} (
            dp_title,
            dp_price,
            dp_likes,
            dp_bag,
            dp_boosted,
            dp_brand,
            dp_url_list,
            dp_men_or_wmn,
            dp_gen_category,
            dp_category,
            dp_size,
            dp_condition,
            dp_images,
            dp_image_len,
            dp_color1,
            dp_color2
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """
    cursor.executemany(command_insert, combined_list)

    # command_create = """
    #     CREATE TABLE IF NOT EXISTS inv_practice (
    #         id INTEGER PRIMARY KEY AUTOINCREMENT,
    #         dp_title TEXT UNIQUE,
    #         dp_price INT,
    #         dp_likes INT,
    #         dp_bag INT,
    #         dp_boosted INT,
    #         dp_brand TEXT,
    #         dp_url_list TEXT,
    #         dp_men_or_wmn TEXT,
    #         dp_gen_category TEXT,
    #         dp_category TEXT,
    #         dp_size TEXT,
    #         dp_condition TEXT,
    #         dp_images TEXT,
    #         dp_image_len INT,
    #         dp_color1 TEXT,
    #         dp_color2 TEXT DEFAULT ''
    #     )
    # """
    # cursor.execute(command_create)
    
    # # Insert data into the new table
    # command_insert = """
    #     INSERT OR IGNORE INTO inv_practice (
    #         dp_title,
    #         dp_price,
    #         dp_likes,
    #         dp_bag,
    #         dp_boosted,
    #         dp_brand,
    #         dp_url_list,
    #         dp_men_or_wmn,
    #         dp_gen_category,
    #         dp_category,
    #         dp_size,
    #         dp_condition,
    #         dp_images,
    #         dp_image_len,
    #         dp_color1,
    #         dp_color2
    #     ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    # """
    # cursor.executemany(command_insert, combined_list)
    
    connection.commit()
    connection.close()


start_up()
sign_in(account_name) #sign in not necessary for this, so this could also be a normal active scraper
scroll_down_script()
each_post()
checking_all_match()
sqlite_database_for_depop(account_name)



# now just need a selenium auto scraper to  go through every single post, save the title to a list, compared the titles to each list, 
# maybe create a zipped file with enumeration as well to easily identify it easier, like in sql, title could be unique id
# actually enumaration might not be needed, since titles will just be compared
#can make a database, maybe using sql, to compared all listings from all platforms,
# if its sold on one platform, must be sold on all, so that would be good to like check it every day and if it is sold on one,
# runs program to list it as sold on other platforms.

# Once I am able to extract the text from the script tag, then I am able to get the rest of the info I need, including pics, the # of pics, price and name, then can start uploading all of my items into the sql database.

# Focus more on input, and output will come with it.

#issues currently is the scroll down script is having an issue where its not scrolling all the way down for some reason, maybe instead I can just use the load_more execute script to go until the button is pressable then
# press it with that, also the likes is messing up too, not giving me the value I need, and not sure on how to extract it either.
#still need to find a way to see how long this post has been up, but at the moment I cant seem to find a way, maybe I'll just look through the code on the page, and see if it is hidden somewhere there, bc it only gives me the
# last time it was relisted, and that is not accurate at all, overall this works great now, ready to enter into sql, but that is also something I will need to learn how to do as well.

#once i get this database working, then how else would I need to interact with it,
# moving sold posts, from depop_inventory to depop_sold
# creating a sold database to move it into so I dont just loose all the info

#error with hats, so I will need to fix it.  Becuase there are no size with hats, and must enter that as a blank,
#maybe I can assign it to be fixed by identifying if it is a hat, and if it is, rewrite the function to accomodate for that
# shoes are good, so its just an issue with items that don't need/have a size

#that issue has been fixed and is even better now with using the data-testid rather than the class attribute, so much more accurate and less code,
# Current Errors:
# trying to skip the meet the seller post with identifying the price of 99999.00, but im doing something wrong.  The price is staying 99999.00 for every other post, it is not refreshing, so maybe
# theres a piece of code im using in the function that restores everything, bc even after resetting the variable, it still stays at 99999.00, so will work on that tmrw

#script now works but since I need to  click on the page to open it up, maybe I can leave the og page as it, create new tab, extract, then close that 2nd page and continue with the first page.

#OK so i got it to open a new tab, but the url is off and is sending me a 404 error, need to figure out how to get the correct url for the post just off the page, 
#ok have figured out where I could find that url, then I would just have to replace "/products/realvintage_-" with 0 the I'll have the end of the link, which is the only dynamic part I will need to open a new tab with 
#the proper url, so tmrw I will need to figure out how to extract the href from the element, but so far so good, once I figure that out, then everything else will be cake and I can finally start creating a big database
#with all my posts.

# 3-10-23
# finally figured out the whole tab situation and now have this script almost ready to run, I want to make it better, I want to parse through the title and edit to add a brand if needed, since most of my objects dont contains a brand at all
# also be able to identify if this item is in someones bag as well, just as another factor I could use to get more info out of my products, like the like filter but better, since it being in the bag indicates someone wants to buy it

#small issue with meet the seller, I believe i fixed it, but need to double check, wasnt able to test it
# need to figure out the brand issue, identify whether or not there is a brand, fix that last else statement in that section and fix it
# then once i fix the brand issue, then I am all done, and can successfully start running the script and creating a depop database for all my listings, then have to do the same thing to grailed, then ebay maybe?
# ebay might already have an option to download all listings so I could just use that, regardless it is good practice,  this took a lot of work, maybe like 20-30 hrs overall, if i was to make an estimate, epecially this wweek
# I was only working on this project all week, so Im glad I am able to fix it correctly, yeah cause when jacob came on tuesday, i was working on it, and worked on it the day before as well

